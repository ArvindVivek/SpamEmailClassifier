{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLSpamEmailClassifier-Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW5aCi53rruy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d8d91eb6-4b90-4769-ec01-802029c14095"
      },
      "source": [
        "# Sources\n",
        "# https://medium.com/@randerson112358/email-spam-detection-using-python-machine-learning-abe38c889855\n",
        "# https://www.kaggle.com/balakishan77/spam-or-ham-email-classification\n",
        "\n",
        "#Import all necessary libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
        "import string\n",
        "\n",
        "dataset = pd.read_csv('emails.csv')\n",
        "\n",
        "#Exploratory Data Analysis\n",
        "dataset.drop_duplicates(inplace = True)\n",
        "print(dataset.head(4))\n",
        "print(dataset.columns)\n",
        "print(dataset.shape)\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Tokenization Process\n",
        "def nlp_processing(inText):\n",
        "  remove_punc = [char for char in inText if char not in string.punctuation]\n",
        "  remove_punc = ''.join(remove_punc)\n",
        "  remove_stop = [word for word in remove_punc.split() if word.lower() not in stopwords.words('english')]\n",
        "\n",
        "  return remove_stop\n",
        "\n",
        "print(dataset['text'].head().apply(nlp_processing))\n",
        "\n",
        "# Use CountVectorizer to convert text into tokens\n",
        "text_tokenized = CountVectorizer(analyzer=nlp_processing).fit_transform(dataset['text'])\n",
        "\n",
        "# Split data into test and train sets: 80% train and 20% test\n",
        "x_train, x_test, y_train, y_test = train_test_split(text_tokenized, dataset['spam'], test_size=0.2, random_state=0)\n",
        "\n",
        "# Create and train Naive Bayes classifier\n",
        "ML_classifier = MultinomialNB()\n",
        "ML_classifier.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                text  spam\n",
            "0  Subject: naturally irresistible your corporate...     1\n",
            "1  Subject: the stock trading gunslinger  fanny i...     1\n",
            "2  Subject: unbelievable new homes made easy  im ...     1\n",
            "3  Subject: 4 color printing special  request add...     1\n",
            "Index(['text', 'spam'], dtype='object')\n",
            "(5695, 2)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "0    [Subject, naturally, irresistible, corporate, ...\n",
            "1    [Subject, stock, trading, gunslinger, fanny, m...\n",
            "2    [Subject, unbelievable, new, homes, made, easy...\n",
            "3    [Subject, 4, color, printing, special, request...\n",
            "4    [Subject, money, get, software, cds, software,...\n",
            "Name: text, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLy5QwI9vmUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b954ac7-b5fd-4df9-8193-e50cba7f7017"
      },
      "source": [
        "# Evaluating training prediction\n",
        "prediction = ML_classifier.predict(x_train)\n",
        "print('Train Accuracy: ', accuracy_score(y_train, prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9971466198419666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8heyrJbx-zZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17a30edd-a558-403f-a443-3109fb2a8b08"
      },
      "source": [
        "# Evaluating testing prediction\n",
        "prediction_test =  ML_classifier.predict(x_test)\n",
        "print('Test Accuracy: ', accuracy_score(y_test, prediction_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.9920983318700615\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}